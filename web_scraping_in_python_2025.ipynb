{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ead7bdb",
   "metadata": {},
   "source": [
    "# Web Scraping in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c601ffb7",
   "metadata": {},
   "source": [
    "## Setting up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33921b6",
   "metadata": {},
   "source": [
    "Install the packages we will use today.\n",
    "We'll need\n",
    "- requests, to get the HTML content of a web page\n",
    "- BeautifulSoup, which is used to parse HTML into a manipulable object in Python\n",
    "- pandas, to work with dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216d63b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install beautifulsoup4 requests pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2f1f1f",
   "metadata": {},
   "source": [
    "And let's import them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf7ede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5b281d",
   "metadata": {},
   "source": [
    "## Scraping a single page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d668f16",
   "metadata": {},
   "source": [
    "### Downloading HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3b4eac",
   "metadata": {},
   "source": [
    "Let's start by scraping some content from the RBloggers webpage, which contains information and tutorials for R.\n",
    "\n",
    "The first step is to download the HTML for a webpage using `requests.get`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235cfd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\n",
    "\turl='https://www.r-bloggers.com'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f74b62",
   "metadata": {},
   "source": [
    "We can view the HTML code that we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1504bdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0361449b",
   "metadata": {},
   "source": [
    "What you saw above is the actual HTML code underlying the webpage on your browser. However, this is currently just text (string). To make it easier to work with, we will use BeautifulSoup to turn it into an object that allows us to extract information easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb033ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "webpage = BeautifulSoup(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55e18c6",
   "metadata": {},
   "source": [
    "### Scraping text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e835cf6b",
   "metadata": {},
   "source": [
    "Let's create a new variable for the page's logo as text using the CSS selector to identify it. (Hint: SelectorGadget can make this easier!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4a74e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_logo = webpage.select_one('.logo-wrap').get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e48ba9",
   "metadata": {},
   "source": [
    "Print the variable to see what we've downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bdd1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(page_logo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5082183",
   "metadata": {},
   "source": [
    "Chances are you'll want only the text, so you can use `.strip()` to get rid of the surrounding spaces/empty lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179a3003",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(page_logo.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a989507",
   "metadata": {},
   "source": [
    "Changing `select_one` to `select` will select all of the elements with the attribute and save them as a list object. Let's do this for the article title on the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae6a7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_elements = webpage.select('h3 a')\n",
    "title_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f72223",
   "metadata": {},
   "source": [
    "To turn this into a list of texts instead of list of elements, you can use a list comprehension. If you are not familiar with a list comprehension, briefly, it is like a for loop, but more compact (see below for comparison):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd95bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop version:\n",
    "titles = []\n",
    "for title_element in title_elements:\n",
    "\ttitles.append(title_element.get_text())\n",
    "\t\n",
    "# List comprehension version (more compact):\n",
    "titles = [title_element.get_text() for title_element in title_elements]\n",
    "\n",
    "titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8fd5c3",
   "metadata": {},
   "source": [
    "## Scraping images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4b7559",
   "metadata": {},
   "source": [
    "We can do the same thing for images by choosing their HTML selectors and using the `src` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45513a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_elements = webpage.select('img')\n",
    "images = [image_element.get('src') for image_element in image_elements]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30456614",
   "metadata": {},
   "source": [
    "Let's see the first two elements in the list of images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e65527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "images[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82b5270",
   "metadata": {},
   "source": [
    "To see the images themselves, you could follow the links. In a scraping scenario, we often want to download the images, so we will do that.\n",
    "\n",
    "Note that common image file types are: `.png`, `.jpg`, `.jpeg`, `.gif` and `.webp`. The last one is a recent addition and becoming more common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47b22f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_binary = requests.get(images[0]).content\n",
    "\n",
    "# Note the mode 'wb', which tells Python to write the content as binary\n",
    "# This is needed to save things that are not text\n",
    "with open('r_bloggers.webp', 'wb') as f:\n",
    "\tf.write(image_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e623dd4a",
   "metadata": {},
   "source": [
    "## Exercise 1: basic web scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a9a728",
   "metadata": {},
   "source": [
    "On your own, repeat the steps above on the Wikipedia homepage.\n",
    "\n",
    "First, download the HTML for <https://en.wikipedia.org/wiki/Main_Page>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67224621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d62b52",
   "metadata": {},
   "source": [
    "Next, view the HTML code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f62f2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c417178",
   "metadata": {},
   "source": [
    "Scrape the headings for the homepage features ('From today's featured article', 'In the news', etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9844e2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd16d32",
   "metadata": {},
   "source": [
    "Scrape the text of the homepage features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76174eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582db1a6",
   "metadata": {},
   "source": [
    "## More advanced scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b69c05",
   "metadata": {},
   "source": [
    "Often, when undertaking a web scraping project, we find we'll need to download content from multiple pages or multiple locations.\n",
    "\n",
    "The Connosr database contains a variety of whisky reviews, ratings, and information. The website is structured with information nested under the main URL, www.connosr.com.\n",
    "\n",
    "[https://www.connosr.com/](https://www.connosr.com)\n",
    "\n",
    "Here is the structure of the webpage: \n",
    "\n",
    "![StructureWebsite](images/WebsiteStructure.jpg)\n",
    "\n",
    "We're interested in scraping data about Scottish whisky, located in the [Scotch Whiskys sub-folder](https://www.connosr.com/scotch-whisky). Let's save the URL in a new variable:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c984e545",
   "metadata": {},
   "outputs": [],
   "source": [
    "whiskypage = 'https://www.connosr.com/scotch-whisky'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79486a6a",
   "metadata": {},
   "source": [
    "## Level 1: Home Page\n",
    "\n",
    "### Extracting information from links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cf7b2c",
   "metadata": {},
   "source": [
    "Let's get the links to all of the Scottish whisky distilleries listed on the page. Once we have the list, we'll be able to use a spider to 'crawl' through our links one at a time, extracting information about each distillery.\n",
    "\n",
    "We'll use the CSS selector to grab the HTML nodes for the names and the corresponding HTML attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4481e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist_links(url):\n",
    "\thtml = requests.get(url).text\n",
    "\thtml_soup = BeautifulSoup(html)\n",
    "\tname_elements = html_soup.select('.name')\n",
    "\tdist_links = [name_element['href'] for name_element in name_elements]\n",
    "\treturn dist_links\n",
    "\n",
    "dist_links = get_dist_links(whiskypage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb755fb",
   "metadata": {},
   "source": [
    "We can take a peek at the first few links to see that nothing is wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be905fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_links[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f471955",
   "metadata": {},
   "source": [
    "How long is the list of links?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d94459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dist_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0781ab",
   "metadata": {},
   "source": [
    "You may notice that the link isn't actually a full link (with `http...` in front of the link). We will need the full URLs to work with, so we will add the homepage in front of the links using either a loop or list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e5696b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_links = ['http://www.connosr.com' + dist_link for dist_link in dist_links]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068cde35",
   "metadata": {},
   "source": [
    "We can also extract the names of the distilleries. We might write a function for this, simiar to above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407295f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist_names(url):\n",
    "\thtml = requests.get(url).text\n",
    "\thtml_soup = BeautifulSoup(html)\n",
    "\tname_elements = html_soup.select('.name')\n",
    "\tdist_names = [name_element.get_text() for name_element in name_elements]\n",
    "\treturn dist_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ada817",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_names = get_dist_names(whiskypage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95311d38",
   "metadata": {},
   "source": [
    "Note that in practice, you can save some time and space by doing all of these steps in one loop!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65224e0f",
   "metadata": {},
   "source": [
    "### Cleaning scraped text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf87ffd6",
   "metadata": {},
   "source": [
    "Data scraped from the web often needs some cleaning. As the output of the previous block shows us, the distillery names are preceded by an extra letter.\n",
    "\n",
    "Using regex, we'll go ahead and remove the extra letters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4fd9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Compile the pattern in advance to speed things up\n",
    "regex_pattern = re.compile(r'^\\w+\\s')\n",
    "\n",
    "# Create a new list of dist names without the extra letter (and leading space).\n",
    "cleaned_names = []\n",
    "for dist_name in dist_names:\n",
    "\tcleaned_name = regex_pattern.sub('', dist_name)\n",
    "\tcleaned_names.append(cleaned_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765a4475",
   "metadata": {},
   "source": [
    "Let's see how it looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e38c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_names[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6772d",
   "metadata": {},
   "source": [
    "Now, we have a list of the Scottish distilleries in the Connosr database. We might also be interested in seeing how community members have rated them.\n",
    "\n",
    "We can write a function to loop over the webpage that scrapes the rating for each distillery using the HTML nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5448e994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rate_dist(url):\n",
    "\thtml = requests.get(url).text\n",
    "\thtml_soup = BeautifulSoup(html)\n",
    "\tavg_rating_elements = html_soup.select('.not-small-phone')\n",
    "\taverage_rating_texts = [avg_rating_element.get_text() for avg_rating_element in avg_rating_elements]\n",
    "\treturn average_rating_texts\n",
    "\n",
    "rate_dist = get_rate_dist(whiskypage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64dc279",
   "metadata": {},
   "source": [
    "We'll also want to remove the 'Average Rating: ' appended to each distillery's rating, and turn them into actual ratings (i.e. numeric values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e291d3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_rate_dist = [float(rate_text.replace('Average rating: ', '')) for rate_text in rate_dist]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d6a85a",
   "metadata": {},
   "source": [
    "That gives you an error! That's because there's a rating that's not a numerical value (`~`). If you look at the website, it seems like these are whiskies that have no ratings. To handle this, we will have to decide what to do with these values. The best way is to assign them some equivalent of \"NA\". In this case, we will assign them `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7e49a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_rate_dist = []\n",
    "for rate_text in rate_dist:\n",
    "\trating = rate_text.replace('Average rating: ', '')\n",
    "\tif rating == '~':\n",
    "\t\tcleaned_rate_dist.append(None)\n",
    "\telse:\n",
    "\t\tcleaned_rate_dist.append(float(rating))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdc59b7",
   "metadata": {},
   "source": [
    "To save the information we've extracted, we can merge it into a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c01851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "distillery_df = pd.DataFrame(\n",
    "\tzip(full_links, cleaned_names, cleaned_rate_dist),\n",
    "\tcolumns=['full_link', 'cleaned_name', 'rating']\n",
    ")\n",
    "distillery_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb23b07",
   "metadata": {},
   "source": [
    "## Exercise 2: Level 1 scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0132b8",
   "metadata": {},
   "source": [
    "On your own, use what we've learned to scrape a list of whisky distilleries for another region on Connosr.\n",
    "\n",
    "First, save the URL for the page.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e386d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2df8c2",
   "metadata": {},
   "source": [
    "Next, download the links by grabbing the HTML nodes for the names of distilleries and the corresponding HTML attributes. (Hint: we've already defined the function `get_dist_links`in the previous step, so you'll just need to use it on the new URL!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6abb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d344e339",
   "metadata": {},
   "source": [
    "According to the Connosr databased, how many whisky distilleries are in the new region you've explored?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2375bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046c1914",
   "metadata": {},
   "source": [
    "## Level 2: Distilleries pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0ce232",
   "metadata": {},
   "source": [
    "At this point in the lesson, we'll be scraping multiple pages for information. So, you may find that the blocks of code may take longer to run.\n",
    "\n",
    "We're going to repeat the process of writing a function to download the links for reviews for specific bottles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a061a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bottle_links(url):\n",
    "\thtml = requests.get(url).text\n",
    "\thtml_soup = BeautifulSoup(html)\n",
    "\tname_elements = html_soup.select('.name')\n",
    "\tbottle_links = [name_element['href'] for name_element in name_elements]\n",
    "\treturn bottle_links\n",
    "\n",
    "bottle_links = []\n",
    "for full_link in full_links:\n",
    "\tbottle_links += get_bottle_links(full_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe67a9f",
   "metadata": {},
   "source": [
    "### Completing partial URLs\n",
    "\n",
    "The links are incomplete, with only part of the URL path. Let's fix this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615c25de",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_bottle_links = ['http://www.connosr.com' + bottle_link for bottle_link in bottle_links]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57215e4d",
   "metadata": {},
   "source": [
    "Let's look at some of them to see if we got it right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff230c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_bottle_links[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d73eb6",
   "metadata": {},
   "source": [
    "### Extracting information from links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6deab7d1",
   "metadata": {},
   "source": [
    "Now we have the links of each bottle page. We also want to get the name of each bottle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1991c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bottle_names(url):\n",
    "\thtml = requests.get(url).text\n",
    "\thtml_soup = BeautifulSoup(html)\n",
    "\tname_elements = html_soup.select('.name')\n",
    "\tbottle_names = [name_element.get_text() for name_element in name_elements]\n",
    "\treturn bottle_names\n",
    "\n",
    "bottle_names = []\n",
    "for full_link in full_links:\n",
    "\tbottle_names += get_bottle_names(full_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad4b710",
   "metadata": {},
   "source": [
    "## Level 3: Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbca22f0",
   "metadata": {},
   "source": [
    "### Downloading reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bae9b4",
   "metadata": {},
   "source": [
    "The full list of reviewed bottles includes 3,508 observations. To save time, we are going to work on a subset of the list of links. (If you want to work on the full list, please note that it can take up to 10 minutes for each function to run. You can work with the full list by subbing `test_links` with `full_bottle_links`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c6cd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_links = full_bottle_links[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e47e3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bottle_reviews(url):\n",
    "\thtml = requests.get(url).text\n",
    "\thtml_soup = BeautifulSoup(html)\n",
    "\tp_elements = html_soup.select('.simple-review-content p')\n",
    "\tbottle_reviews = [p_element.get_text() for p_element in p_elements]\n",
    "\treturn bottle_reviews\n",
    "\n",
    "bottle_review_list = []\n",
    "for full_bottle_link in test_links:\n",
    "\tbottle_review_list.append(get_bottle_reviews(full_bottle_link))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ff4d23",
   "metadata": {},
   "source": [
    "Now, we have a very long list of reviews! Let's have a look at the reviews for the first bottle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406d79ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottle_review_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dd4dac",
   "metadata": {},
   "source": [
    "### Merging scraped data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f7904c",
   "metadata": {},
   "source": [
    "We may want to merge the reviews for each bottle together. We can do this by joining the strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872f7015",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_by_bottle = [' '.join(bottle_reviews) for bottle_reviews in bottle_review_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d11224",
   "metadata": {},
   "source": [
    "We can also create a dataframe for further data manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e0ddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_bottle_names = pd.DataFrame(\n",
    "\tzip(bottle_names[:100], reviews_by_bottle),\n",
    "\tcolumns=['bottle_name', 'review']\n",
    ")\n",
    "with_bottle_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c2f703",
   "metadata": {},
   "source": [
    "# The end!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
